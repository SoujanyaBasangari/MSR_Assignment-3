{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://paperswithcode.com/task/semantic-segmentation', 'https://paperswithcode.com/task/image-classification', 'https://paperswithcode.com/task/object-detection', 'https://paperswithcode.com/task/image-generation', 'https://paperswithcode.com/task/denoising', 'https://paperswithcode.com/task/language-modelling', 'https://paperswithcode.com/task/machine-translation', 'https://paperswithcode.com/task/question-answering', 'https://paperswithcode.com/task/sentiment-analysis', 'https://paperswithcode.com/task/text-generation', 'https://paperswithcode.com/task/medical-image-segmentation', 'https://paperswithcode.com/task/drug-discovery', 'https://paperswithcode.com/task/lesion-segmentation', 'https://paperswithcode.com/task/brain-tumor-segmentation', 'https://paperswithcode.com/task/covid-19-detection', 'https://paperswithcode.com/task/regression', 'https://paperswithcode.com/task/representation-learning', 'https://paperswithcode.com/task/transfer-learning', 'https://paperswithcode.com/task/word-embeddings', 'https://paperswithcode.com/task/data-augmentation', 'https://paperswithcode.com/task/recommendation-systems', 'https://paperswithcode.com/task/fairness', 'https://paperswithcode.com/task/continual-learning', 'https://paperswithcode.com/task/topic-models', 'https://paperswithcode.com/task/causal-inference', 'https://paperswithcode.com/task/semantic-segmentation', 'https://paperswithcode.com/task/link-prediction', 'https://paperswithcode.com/task/node-classification', 'https://paperswithcode.com/task/graph-embedding', 'https://paperswithcode.com/task/graph-classification', 'https://paperswithcode.com/task/speech-recognition', 'https://paperswithcode.com/task/speech-synthesis', 'https://paperswithcode.com/task/dialogue-generation', 'https://paperswithcode.com/task/speech-enhancement', 'https://paperswithcode.com/task/voice-conversion', 'https://paperswithcode.com/task/time-series', 'https://paperswithcode.com/task/eeg', 'https://paperswithcode.com/task/imputation', 'https://paperswithcode.com/task/time-series-classification', 'https://paperswithcode.com/task/time-series-forecasting', 'https://paperswithcode.com/task/continuous-control', 'https://paperswithcode.com/task/atari-games', 'https://paperswithcode.com/task/starcraft', 'https://paperswithcode.com/task/starcraft-ii', 'https://paperswithcode.com/task/board-games', 'https://paperswithcode.com/task/program-synthesis', 'https://paperswithcode.com/task/text-to-sql', 'https://paperswithcode.com/task/code-generation', 'https://paperswithcode.com/task/type-prediction', 'https://paperswithcode.com/task/program-induction', 'https://paperswithcode.com/task/music-generation', 'https://paperswithcode.com/task/audio-classification', 'https://paperswithcode.com/task/sound-event-detection', 'https://paperswithcode.com/task/audio-generation', 'https://paperswithcode.com/task/acoustic-scene-classification', 'https://paperswithcode.com/task/curriculum-learning', 'https://paperswithcode.com/task/visual-odometry', 'https://paperswithcode.com/task/motion-planning', 'https://paperswithcode.com/task/robot-navigation', 'https://paperswithcode.com/task/human-robot-interaction', 'https://paperswithcode.com/task/knowledge-graphs', 'https://paperswithcode.com/task/knowledge-graph-completion', 'https://paperswithcode.com/task/causal-discovery', 'https://paperswithcode.com/task/knowledge-base-completion', 'https://paperswithcode.com/task/entity-alignment', 'https://paperswithcode.com/task/regression', 'https://paperswithcode.com/task/music-generation', 'https://paperswithcode.com/task/music-information-retrieval', 'https://paperswithcode.com/task/music-source-separation', 'https://paperswithcode.com/task/music-transcription', 'https://paperswithcode.com/task/adversarial-attack', 'https://paperswithcode.com/task/adversarial-defense', 'https://paperswithcode.com/task/data-poisoning', 'https://paperswithcode.com/task/inference-attack', 'https://paperswithcode.com/task/adversarial-text', 'https://paperswithcode.com/task/decision-making', 'https://paperswithcode.com/task/variational-inference', 'https://paperswithcode.com/task/common-sense-reasoning', 'https://paperswithcode.com/task/visual-reasoning', 'https://paperswithcode.com/task/temporal-logic']\n"
     ]
    }
   ],
   "source": [
    "#importing all the required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "session1 = requests.Session()\n",
    "#Repository URL from which we have to extract data\n",
    "url = \"https://paperswithcode.com/sota\"\n",
    "task_links=[]\n",
    "req1 = session1.get(url)\n",
    "bs_2 = BeautifulSoup(req1.text, 'html.parser')\n",
    "#Extracting links which has task information\n",
    "sota_links=bs_2.findAll('a', href = re.compile(r'/task/.*'))\n",
    "#Extracting only links content and appending to list\n",
    "for anchor in sota_links:\n",
    "    href = anchor['href'] \n",
    "    href = 'https://paperswithcode.com' + href\n",
    "    task_links.append(href)\n",
    "print(task_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://paperswithcode.com/paper/hierarchical-multi-scale-attention-for', 'https://paperswithcode.com/paper/hierarchical-multi-scale-attention-for#code', 'https://paperswithcode.com/paper/rethinking-pre-training-and-self-training', 'https://paperswithcode.com/paper/rethinking-pre-training-and-self-training#code', 'https://paperswithcode.com/paper/resnest-split-attention-networks', 'https://paperswithcode.com/paper/resnest-split-attention-networks#code', 'https://paperswithcode.com/paper/resnest-split-attention-networks', 'https://paperswithcode.com/paper/resnest-split-attention-networks#code', 'https://paperswithcode.com/paper/resnest-split-attention-networks', 'https://paperswithcode.com/paper/resnest-split-attention-networks#code', 'https://paperswithcode.com/paper/rethinking-pre-training-and-self-training', 'https://paperswithcode.com/paper/rethinking-pre-training-and-self-training#code', 'https://paperswithcode.com/paper/resnest-split-attention-networks', 'https://paperswithcode.com/paper/resnest-split-attention-networks#code', 'https://paperswithcode.com/paper/point-transformer-1', 'https://paperswithcode.com/paper/point-transformer-1#code', 'https://paperswithcode.com/paper/virtual-multi-view-fusion-for-3d-semantic', 'https://paperswithcode.com/paper/191111236', 'https://paperswithcode.com/paper/191111236#code', 'https://paperswithcode.com/paper/point-transformer-1', 'https://paperswithcode.com/paper/point-transformer-1#code', 'https://paperswithcode.com/paper/improving-semantic-segmentation-via-video', 'https://paperswithcode.com/paper/improving-semantic-segmentation-via-video#code', 'https://paperswithcode.com/paper/scene-segmentation-with-dual-relation-aware', 'https://paperswithcode.com/paper/scene-segmentation-with-dual-relation-aware#code', 'https://paperswithcode.com/paper/efficient-rgb-d-semantic-segmentation-for', 'https://paperswithcode.com/paper/efficient-rgb-d-semantic-segmentation-for#code', 'https://paperswithcode.com/paper/self-correction-for-human-parsing', 'https://paperswithcode.com/paper/self-correction-for-human-parsing#code', 'https://paperswithcode.com/paper/skyscapes-fine-grained-semantic-understanding', 'https://paperswithcode.com/paper/sgpn-similarity-group-proposal-network-for-3d', 'https://paperswithcode.com/paper/sgpn-similarity-group-proposal-network-for-3d#code', 'https://paperswithcode.com/paper/cascadepsp-toward-class-agnostic-and-very', 'https://paperswithcode.com/paper/cascadepsp-toward-class-agnostic-and-very#code', 'https://paperswithcode.com/paper/self-supervised-model-adaptation-for', 'https://paperswithcode.com/paper/self-supervised-model-adaptation-for#code', 'https://paperswithcode.com/paper/efficient-rgb-d-semantic-segmentation-for', 'https://paperswithcode.com/paper/efficient-rgb-d-semantic-segmentation-for#code', 'https://paperswithcode.com/paper/prototypical-pseudo-label-denoising-and', 'https://paperswithcode.com/paper/self-supervised-model-adaptation-for', 'https://paperswithcode.com/paper/self-supervised-model-adaptation-for#code', 'https://paperswithcode.com/paper/self-supervised-model-adaptation-for', 'https://paperswithcode.com/paper/self-supervised-model-adaptation-for#code', 'https://paperswithcode.com/paper/cloud-net-a-cloud-segmentation-cnn-for', 'https://paperswithcode.com/paper/cloud-net-a-cloud-segmentation-cnn-for#code', 'https://paperswithcode.com/paper/global-aggregation-then-local-distribution-in', 'https://paperswithcode.com/paper/global-aggregation-then-local-distribution-in#code', 'https://paperswithcode.com/paper/skyscapes-fine-grained-semantic-understanding', 'https://paperswithcode.com/paper/what-s-there-in-the-dark', 'https://paperswithcode.com/paper/what-s-there-in-the-dark#code', 'https://paperswithcode.com/paper/rellis-3d-dataset-data-benchmarks-and', 'https://paperswithcode.com/paper/rellis-3d-dataset-data-benchmarks-and#code', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural#code', 'https://paperswithcode.com/paper/improving-semantic-segmentation-via-video', 'https://paperswithcode.com/paper/improving-semantic-segmentation-via-video#code', 'https://paperswithcode.com/paper/fasterseg-searching-for-faster-real-time-1', 'https://paperswithcode.com/paper/fasterseg-searching-for-faster-real-time-1#code', 'https://paperswithcode.com/paper/a-sim2real-deep-learning-approach-for-the', 'https://paperswithcode.com/paper/a-sim2real-deep-learning-approach-for-the#code', 'https://paperswithcode.com/paper/inter-region-affinity-distillation-for-road', 'https://paperswithcode.com/paper/inter-region-affinity-distillation-for-road#code', 'https://paperswithcode.com/paper/plugin-networks-for-inference-under-partial', 'https://paperswithcode.com/paper/plugin-networks-for-inference-under-partial#code', 'https://paperswithcode.com/paper/what-s-there-in-the-dark', 'https://paperswithcode.com/paper/what-s-there-in-the-dark#code', 'https://paperswithcode.com/paper/foreground-aware-relation-network-for-1', 'https://paperswithcode.com/paper/foreground-aware-relation-network-for-1#code', 'https://paperswithcode.com/paper/aerial-imagery-pixel-level-segmentation', 'https://paperswithcode.com/paper/aerial-imagery-pixel-level-segmentation#code', 'https://paperswithcode.com/paper/uvid-net-enhanced-semantic-segmentation-of', 'https://paperswithcode.com/paper/kpconv-flexible-and-deformable-convolution', 'https://paperswithcode.com/paper/kpconv-flexible-and-deformable-convolution#code', 'https://paperswithcode.com/paper/efficientseg-an-efficient-semantic', 'https://paperswithcode.com/paper/efficientseg-an-efficient-semantic#code', 'https://paperswithcode.com/paper/meta-pseudo-labels', 'https://paperswithcode.com/paper/meta-pseudo-labels#code', 'https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1', 'https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1#code', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code', 'https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1', 'https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1#code', 'https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1', 'https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1#code', 'https://paperswithcode.com/paper/a-branching-and-merging-convolutional-network', 'https://paperswithcode.com/paper/a-branching-and-merging-convolutional-network#code', 'https://paperswithcode.com/paper/scaling-up-visual-and-vision-language', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code', 'https://paperswithcode.com/paper/meta-pseudo-labels', 'https://paperswithcode.com/paper/meta-pseudo-labels#code', 'https://paperswithcode.com/paper/sequential-random-network-for-fine-grained', 'https://paperswithcode.com/paper/augmentation-strategies-for-learning-with', 'https://paperswithcode.com/paper/augmentation-strategies-for-learning-with#code', 'https://paperswithcode.com/paper/grafit-learning-fine-grained-image', 'https://paperswithcode.com/paper/fine-tuning-darts-for-image-classification', 'https://paperswithcode.com/paper/neural-architecture-transfer', 'https://paperswithcode.com/paper/neural-architecture-transfer#code', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code', 'https://paperswithcode.com/paper/edge-labeling-graph-neural-network-for-few', 'https://paperswithcode.com/paper/edge-labeling-graph-neural-network-for-few#code', 'https://paperswithcode.com/paper/large-scale-learning-of-general-visual', 'https://paperswithcode.com/paper/large-scale-learning-of-general-visual#code', 'https://paperswithcode.com/paper/efficient-capsnet-capsule-network-with-self', 'https://paperswithcode.com/paper/efficient-capsnet-capsule-network-with-self#code', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code', 'https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy', 'https://paperswithcode.com/paper/fixing-the-train-test-resolution-discrepancy#code', 'https://paperswithcode.com/paper/large-scale-learning-of-general-visual', 'https://paperswithcode.com/paper/large-scale-learning-of-general-visual#code', 'https://paperswithcode.com/paper/a-closer-look-at-art-mediums-the-mame-image', 'https://paperswithcode.com/paper/a-closer-look-at-art-mediums-the-mame-image#code', 'https://paperswithcode.com/paper/direction-concentration-learning-enhancing', 'https://paperswithcode.com/paper/direction-concentration-learning-enhancing#code', 'https://paperswithcode.com/paper/null-sampling-for-interpretable-and-fair', 'https://paperswithcode.com/paper/null-sampling-for-interpretable-and-fair#code', 'https://paperswithcode.com/paper/webly-supervised-image-classification-with', 'https://paperswithcode.com/paper/sequential-random-network-for-fine-grained', 'https://paperswithcode.com/paper/ufpr-periocular-a-periocular-dataset', 'https://paperswithcode.com/paper/cleannet-transfer-learning-for-scalable-image', 'https://paperswithcode.com/paper/cleannet-transfer-learning-for-scalable-image#code', 'https://paperswithcode.com/paper/pcgan-char-progressively-trained-classifier', 'https://paperswithcode.com/paper/pcgan-char-progressively-trained-classifier', 'https://paperswithcode.com/paper/pcgan-char-progressively-trained-classifier', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1', 'https://paperswithcode.com/paper/spinalnet-deep-neural-network-with-gradual-1#code', 'https://paperswithcode.com/paper/upanets-learning-from-the-universal-pixel', 'https://paperswithcode.com/paper/upanets-learning-from-the-universal-pixel#code', 'https://paperswithcode.com/paper/classification-of-fracture-and-normal', 'https://paperswithcode.com/paper/classification-of-fracture-and-normal#code', 'https://paperswithcode.com/paper/msmatch-semi-supervised-multispectral-scene', 'https://paperswithcode.com/paper/msmatch-semi-supervised-multispectral-scene#code', 'https://paperswithcode.com/paper/dynamic-routing-between-capsules', 'https://paperswithcode.com/paper/dynamic-routing-between-capsules#code', 'https://paperswithcode.com/paper/rethinking-recurrent-neural-networks-and', 'https://paperswithcode.com/paper/rethinking-recurrent-neural-networks-and#code', 'https://paperswithcode.com/paper/autodropout-learning-dropout-patterns-to', 'https://paperswithcode.com/paper/autodropout-learning-dropout-patterns-to#code', 'https://paperswithcode.com/paper/autodropout-learning-dropout-patterns-to', 'https://paperswithcode.com/paper/autodropout-learning-dropout-patterns-to#code', 'https://paperswithcode.com/paper/early-learning-regularization-prevents', 'https://paperswithcode.com/paper/early-learning-regularization-prevents#code', 'https://paperswithcode.com/paper/learning-from-crowds-by-modeling-common', 'https://paperswithcode.com/paper/learning-from-crowds-by-modeling-common#code', 'https://paperswithcode.com/paper/image-and-text-fusion-for-upmc-food-101-using', 'https://paperswithcode.com/paper/image-and-text-fusion-for-upmc-food-101-using#code', 'https://paperswithcode.com/paper/rethinking-recurrent-neural-networks-and', 'https://paperswithcode.com/paper/rethinking-recurrent-neural-networks-and#code', 'https://paperswithcode.com/paper/sequential-random-network-for-fine-grained', 'https://paperswithcode.com/paper/sequential-random-network-for-fine-grained', 'https://paperswithcode.com/paper/simple-copy-paste-is-a-strong-data', 'https://paperswithcode.com/paper/simple-copy-paste-is-a-strong-data#code', 'https://paperswithcode.com/paper/simple-copy-paste-is-a-strong-data', 'https://paperswithcode.com/paper/simple-copy-paste-is-a-strong-data#code', 'https://paperswithcode.com/paper/simple-copy-paste-is-a-strong-data', 'https://paperswithcode.com/paper/simple-copy-paste-is-a-strong-data#code', 'https://paperswithcode.com/paper/beta-r-cnn-looking-into-pedestrian-detection', 'https://paperswithcode.com/paper/beta-r-cnn-looking-into-pedestrian-detection#code', 'https://paperswithcode.com/paper/patch-refinement-localized-3d-object', 'https://paperswithcode.com/paper/spotnet-self-attention-multi-task-network-for', 'https://paperswithcode.com/paper/spotnet-self-attention-multi-task-network-for#code', 'https://paperswithcode.com/paper/patch-refinement-localized-3d-object', 'https://paperswithcode.com/paper/patch-refinement-localized-3d-object', 'https://paperswithcode.com/paper/iterdet-iterative-scheme-for-objectdetection', 'https://paperswithcode.com/paper/iterdet-iterative-scheme-for-objectdetection#code', 'https://paperswithcode.com/paper/ssd-single-shot-multibox-detector', 'https://paperswithcode.com/paper/ssd-single-shot-multibox-detector#code', 'https://paperswithcode.com/paper/scene-graph-generation-from-objects-phrases', 'https://paperswithcode.com/paper/scene-graph-generation-from-objects-phrases#code', 'https://paperswithcode.com/paper/radar-rgb-attentive-fusion-for-robust-object', 'https://paperswithcode.com/paper/radar-rgb-attentive-fusion-for-robust-object#code', 'https://paperswithcode.com/paper/spotnet-self-attention-multi-task-network-for', 'https://paperswithcode.com/paper/spotnet-self-attention-multi-task-network-for#code', 'https://paperswithcode.com/paper/detecting-people-in-artwork-with-cnns', 'https://paperswithcode.com/paper/detecting-people-in-artwork-with-cnns#code', 'https://paperswithcode.com/paper/on-generalizing-detection-models-for', 'https://paperswithcode.com/paper/on-generalizing-detection-models-for#code', 'https://paperswithcode.com/paper/on-generalizing-detection-models-for', 'https://paperswithcode.com/paper/on-generalizing-detection-models-for#code', 'https://paperswithcode.com/paper/attention-based-joint-detection-of-object-and', 'https://paperswithcode.com/paper/attention-based-joint-detection-of-object-and#code', 'https://paperswithcode.com/paper/how-to-extract-fashion-trends-from-social', 'https://paperswithcode.com/paper/how-to-extract-fashion-trends-from-social#code', 'https://paperswithcode.com/paper/oriented-object-detection-in-aerial-images', 'https://paperswithcode.com/paper/oriented-object-detection-in-aerial-images#code', 'https://paperswithcode.com/paper/vote3deep-fast-object-detection-in-3d-point', 'https://paperswithcode.com/paper/vote3deep-fast-object-detection-in-3d-point', 'https://paperswithcode.com/paper/vote3deep-fast-object-detection-in-3d-point', 'https://paperswithcode.com/paper/vote3deep-fast-object-detection-in-3d-point', 'https://paperswithcode.com/paper/vote3deep-fast-object-detection-in-3d-point', 'https://paperswithcode.com/paper/vote3deep-fast-object-detection-in-3d-point', 'https://paperswithcode.com/paper/fornax-3d-project-automated-detection-of', 'https://paperswithcode.com/paper/fornax-3d-project-automated-detection-of#code', 'https://paperswithcode.com/paper/slender-object-detection-diagnoses-and', 'https://paperswithcode.com/paper/slender-object-detection-diagnoses-and#code', 'https://paperswithcode.com/paper/simple-copy-paste-is-a-strong-data', 'https://paperswithcode.com/paper/simple-copy-paste-is-a-strong-data#code', 'https://paperswithcode.com/paper/score-based-generative-modeling-through-1', 'https://paperswithcode.com/paper/score-based-generative-modeling-through-1#code', 'https://paperswithcode.com/paper/image-transformer', 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for', 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for#code', 'https://paperswithcode.com/paper/efficient-content-based-sparse-attention-with-1', 'https://paperswithcode.com/paper/efficient-content-based-sparse-attention-with-1#code', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of#code', 'https://paperswithcode.com/paper/generating-high-fidelity-images-with-subscale', 'https://paperswithcode.com/paper/transgan-two-transformers-can-make-one-strong', 'https://paperswithcode.com/paper/transgan-two-transformers-can-make-one-strong#code', 'https://paperswithcode.com/paper/locally-masked-convolution-for-autoregressive', 'https://paperswithcode.com/paper/locally-masked-convolution-for-autoregressive#code', 'https://paperswithcode.com/paper/locally-masked-convolution-for-autoregressive', 'https://paperswithcode.com/paper/locally-masked-convolution-for-autoregressive#code', 'https://paperswithcode.com/paper/training-generative-adversarial-networks-with-2', 'https://paperswithcode.com/paper/training-generative-adversarial-networks-with-2#code', 'https://paperswithcode.com/paper/a-u-net-based-discriminator-for-generative', 'https://paperswithcode.com/paper/a-u-net-based-discriminator-for-generative#code', 'https://paperswithcode.com/paper/image-generators-with-conditionally', 'https://paperswithcode.com/paper/image-generators-with-conditionally#code', 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for', 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for#code', 'https://paperswithcode.com/paper/large-scale-gan-training-for-high-fidelity', 'https://paperswithcode.com/paper/large-scale-gan-training-for-high-fidelity#code', 'https://paperswithcode.com/paper/ncp-vae-variational-autoencoders-with-noise-1', 'https://paperswithcode.com/paper/generative-adversarial-transformers', 'https://paperswithcode.com/paper/generative-adversarial-transformers#code', 'https://paperswithcode.com/paper/generative-adversarial-transformers', 'https://paperswithcode.com/paper/generative-adversarial-transformers#code', 'https://paperswithcode.com/paper/vaebm-a-symbiosis-between-variational', 'https://paperswithcode.com/paper/progressive-growing-of-gans-for-improved', 'https://paperswithcode.com/paper/progressive-growing-of-gans-for-improved#code', 'https://paperswithcode.com/paper/twin-auxilary-classifiers-gan', 'https://paperswithcode.com/paper/twin-auxilary-classifiers-gan#code', 'https://paperswithcode.com/paper/generative-latent-flow-a-framework-for-non', 'https://paperswithcode.com/paper/generative-latent-flow-a-framework-for-non#code', 'https://paperswithcode.com/paper/vaebm-a-symbiosis-between-variational', 'https://paperswithcode.com/paper/finegan-unsupervised-hierarchical', 'https://paperswithcode.com/paper/finegan-unsupervised-hierarchical#code', 'https://paperswithcode.com/paper/finegan-unsupervised-hierarchical', 'https://paperswithcode.com/paper/finegan-unsupervised-hierarchical#code', 'https://paperswithcode.com/paper/finegan-unsupervised-hierarchical', 'https://paperswithcode.com/paper/finegan-unsupervised-hierarchical#code', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of#code', 'https://paperswithcode.com/paper/a-u-net-based-discriminator-for-generative', 'https://paperswithcode.com/paper/a-u-net-based-discriminator-for-generative#code', 'https://paperswithcode.com/paper/differentiable-augmentation-for-data', 'https://paperswithcode.com/paper/differentiable-augmentation-for-data#code', 'https://paperswithcode.com/paper/differentiable-augmentation-for-data', 'https://paperswithcode.com/paper/differentiable-augmentation-for-data#code', 'https://paperswithcode.com/paper/the-relativistic-discriminator-a-key-element', 'https://paperswithcode.com/paper/the-relativistic-discriminator-a-key-element#code', 'https://paperswithcode.com/paper/coco-gan-generation-by-parts-via-conditional', 'https://paperswithcode.com/paper/coco-gan-generation-by-parts-via-conditional#code', 'https://paperswithcode.com/paper/gans-trained-by-a-two-time-scale-update-rule', 'https://paperswithcode.com/paper/gans-trained-by-a-two-time-scale-update-rule#code', 'https://paperswithcode.com/paper/training-generative-adversarial-networks-with-2', 'https://paperswithcode.com/paper/training-generative-adversarial-networks-with-2#code', 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for', 'https://paperswithcode.com/paper/a-style-based-generator-architecture-for#code', 'https://paperswithcode.com/paper/semantic-bottleneck-scene-generation', 'https://paperswithcode.com/paper/semantic-bottleneck-scene-generation#code', 'https://paperswithcode.com/paper/semantic-bottleneck-scene-generation', 'https://paperswithcode.com/paper/semantic-bottleneck-scene-generation#code', 'https://paperswithcode.com/paper/semantic-bottleneck-scene-generation', 'https://paperswithcode.com/paper/semantic-bottleneck-scene-generation#code', 'https://paperswithcode.com/paper/msg-gan-multi-scale-gradients-gan-for-more', 'https://paperswithcode.com/paper/msg-gan-multi-scale-gradients-gan-for-more#code', 'https://paperswithcode.com/paper/msg-gan-multi-scale-gradients-gan-for-more', 'https://paperswithcode.com/paper/msg-gan-multi-scale-gradients-gan-for-more#code', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of#code', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of#code', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of', 'https://paperswithcode.com/paper/analyzing-and-improving-the-image-quality-of#code', 'https://paperswithcode.com/paper/genesis-generative-scene-inference-and', 'https://paperswithcode.com/paper/genesis-generative-scene-inference-and#code', 'https://paperswithcode.com/paper/genesis-generative-scene-inference-and', 'https://paperswithcode.com/paper/genesis-generative-scene-inference-and#code', 'https://paperswithcode.com/paper/image-generators-with-conditionally', 'https://paperswithcode.com/paper/image-generators-with-conditionally#code', 'https://paperswithcode.com/paper/image-generators-with-conditionally', 'https://paperswithcode.com/paper/image-generators-with-conditionally#code', 'https://paperswithcode.com/paper/image-generators-with-conditionally', 'https://paperswithcode.com/paper/image-generators-with-conditionally#code', 'https://paperswithcode.com/paper/dual-contradistinctive-generative-autoencoder-1', 'https://paperswithcode.com/paper/anycost-gans-for-interactive-image-synthesis', 'https://paperswithcode.com/paper/anycost-gans-for-interactive-image-synthesis#code', 'https://paperswithcode.com/paper/anycost-gans-for-interactive-image-synthesis', 'https://paperswithcode.com/paper/anycost-gans-for-interactive-image-synthesis#code', 'https://paperswithcode.com/paper/when-awgn-based-denoiser-meets-real-noises', 'https://paperswithcode.com/paper/when-awgn-based-denoiser-meets-real-noises#code', 'https://paperswithcode.com/paper/edcnn-edge-enhancement-based-densely', 'https://paperswithcode.com/paper/edcnn-edge-enhancement-based-densely#code', 'https://paperswithcode.com/paper/megatron-lm-training-multi-billion-parameter', 'https://paperswithcode.com/paper/megatron-lm-training-multi-billion-parameter#code', 'https://paperswithcode.com/paper/language-models-are-few-shot-learners', 'https://paperswithcode.com/paper/language-models-are-few-shot-learners#code', 'https://paperswithcode.com/paper/language-models-are-unsupervised-multitask', 'https://paperswithcode.com/paper/language-models-are-unsupervised-multitask#code', 'https://paperswithcode.com/paper/language-models-are-unsupervised-multitask', 'https://paperswithcode.com/paper/language-models-are-unsupervised-multitask#code', 'https://paperswithcode.com/paper/language-models-are-unsupervised-multitask', 'https://paperswithcode.com/paper/language-models-are-unsupervised-multitask#code', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from#code', 'https://paperswithcode.com/paper/dynamic-evaluation-of-transformer-language', 'https://paperswithcode.com/paper/dynamic-evaluation-of-transformer-language#code', 'https://paperswithcode.com/paper/mogrifier-lstm', 'https://paperswithcode.com/paper/mogrifier-lstm#code', 'https://paperswithcode.com/paper/language-models-are-few-shot-learners', 'https://paperswithcode.com/paper/language-models-are-few-shot-learners#code', 'https://paperswithcode.com/paper/language-models-are-few-shot-learners', 'https://paperswithcode.com/paper/language-models-are-few-shot-learners#code', 'https://paperswithcode.com/paper/pay-attention-when-required', 'https://paperswithcode.com/paper/pay-attention-when-required#code', 'https://paperswithcode.com/paper/understanding-back-translation-at-scale', 'https://paperswithcode.com/paper/understanding-back-translation-at-scale#code', 'https://paperswithcode.com/paper/very-deep-transformers-for-neural-machine', 'https://paperswithcode.com/paper/very-deep-transformers-for-neural-machine#code', 'https://paperswithcode.com/paper/delight-very-deep-and-light-weight', 'https://paperswithcode.com/paper/delight-very-deep-and-light-weight#code', 'https://paperswithcode.com/paper/a-simple-but-tough-to-beat-data-augmentation', 'https://paperswithcode.com/paper/a-simple-but-tough-to-beat-data-augmentation#code', 'https://paperswithcode.com/paper/improving-neural-language-modeling-via', 'https://paperswithcode.com/paper/improving-neural-language-modeling-via#code', 'https://paperswithcode.com/paper/language-models-not-just-for-pre-training', 'https://paperswithcode.com/paper/language-models-not-just-for-pre-training#code', 'https://paperswithcode.com/paper/incorporating-a-local-translation-mechanism', 'https://paperswithcode.com/paper/incorporating-a-local-translation-mechanism#code', 'https://paperswithcode.com/paper/multi-agent-dual-learning', 'https://paperswithcode.com/paper/191013267', 'https://paperswithcode.com/paper/191013267#code', 'https://paperswithcode.com/paper/attention-is-all-you-need', 'https://paperswithcode.com/paper/attention-is-all-you-need#code', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems#code', 'https://paperswithcode.com/paper/neural-machine-translation-in-linear-time', 'https://paperswithcode.com/paper/neural-machine-translation-in-linear-time#code', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems#code', 'https://paperswithcode.com/paper/impact-of-corpora-quality-on-neural-machine', 'https://paperswithcode.com/paper/impact-of-corpora-quality-on-neural-machine#code', 'https://paperswithcode.com/paper/pay-less-attention-with-lightweight-and', 'https://paperswithcode.com/paper/pay-less-attention-with-lightweight-and#code', 'https://paperswithcode.com/paper/the-university-of-sydneys-machine-translation', 'https://paperswithcode.com/paper/neural-machine-translation', 'https://paperswithcode.com/paper/neural-machine-translation#code', 'https://paperswithcode.com/paper/facebook-fairs-wmt19-news-translation-task', 'https://paperswithcode.com/paper/facebook-fairs-wmt19-news-translation-task#code', 'https://paperswithcode.com/paper/the-evolved-transformer', 'https://paperswithcode.com/paper/the-evolved-transformer#code', 'https://paperswithcode.com/paper/neural-machine-translation-of-rare-words-with', 'https://paperswithcode.com/paper/neural-machine-translation-of-rare-words-with#code', 'https://paperswithcode.com/paper/sequence-level-knowledge-distillation', 'https://paperswithcode.com/paper/sequence-level-knowledge-distillation#code', 'https://paperswithcode.com/paper/using-lstm-to-translate-french-to-senegalese', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems#code', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems#code', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems', 'https://paperswithcode.com/paper/edinburgh-neural-machine-translation-systems#code', 'https://paperswithcode.com/paper/tildes-machine-translation-systems-for-wmt', 'https://paperswithcode.com/paper/tildes-machine-translation-systems-for-wmt#code', 'https://paperswithcode.com/paper/impact-of-corpora-quality-on-neural-machine', 'https://paperswithcode.com/paper/impact-of-corpora-quality-on-neural-machine#code', 'https://paperswithcode.com/paper/tildes-machine-translation-systems-for-wmt', 'https://paperswithcode.com/paper/tildes-machine-translation-systems-for-wmt#code', 'https://paperswithcode.com/paper/training-and-adapting-multilingual-nmt-for', 'https://paperswithcode.com/paper/training-and-adapting-multilingual-nmt-for#code', 'https://paperswithcode.com/paper/impact-of-corpora-quality-on-neural-machine', 'https://paperswithcode.com/paper/impact-of-corpora-quality-on-neural-machine#code', 'https://paperswithcode.com/paper/training-and-adapting-multilingual-nmt-for', 'https://paperswithcode.com/paper/training-and-adapting-multilingual-nmt-for#code', 'https://paperswithcode.com/paper/the-university-of-sydneys-machine-translation', 'https://paperswithcode.com/paper/the-university-of-sydneys-machine-translation', 'https://paperswithcode.com/paper/the-university-of-sydneys-machine-translation', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from#code', 'https://paperswithcode.com/paper/bp-transformer-modelling-long-range-context', 'https://paperswithcode.com/paper/bp-transformer-modelling-long-range-context#code', 'https://paperswithcode.com/paper/exploiting-monolingual-data-at-scale-for', 'https://paperswithcode.com/paper/delight-very-deep-and-light-weight', 'https://paperswithcode.com/paper/delight-very-deep-and-light-weight#code', 'https://paperswithcode.com/paper/muse-parallel-multi-scale-attention-for', 'https://paperswithcode.com/paper/muse-parallel-multi-scale-attention-for#code', 'https://paperswithcode.com/paper/designing-the-business-conversation-corpus-1', 'https://paperswithcode.com/paper/designing-the-business-conversation-corpus-1#code', 'https://paperswithcode.com/paper/designing-the-business-conversation-corpus-1', 'https://paperswithcode.com/paper/designing-the-business-conversation-corpus-1#code', 'https://paperswithcode.com/paper/191013267', 'https://paperswithcode.com/paper/191013267#code', 'https://paperswithcode.com/paper/191013267', 'https://paperswithcode.com/paper/191013267#code', 'https://paperswithcode.com/paper/191013267', 'https://paperswithcode.com/paper/191013267#code', 'https://paperswithcode.com/paper/191013267', 'https://paperswithcode.com/paper/191013267#code', 'https://paperswithcode.com/paper/on-automatic-parsing-of-log-records', 'https://paperswithcode.com/paper/on-automatic-parsing-of-log-records#code', 'https://paperswithcode.com/paper/on-automatic-parsing-of-log-records', 'https://paperswithcode.com/paper/on-automatic-parsing-of-log-records#code', 'https://paperswithcode.com/paper/on-automatic-parsing-of-log-records', 'https://paperswithcode.com/paper/on-automatic-parsing-of-log-records#code', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from#code', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from#code', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from#code', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from', 'https://paperswithcode.com/paper/omninet-omnidirectional-representations-from#code', 'https://paperswithcode.com/paper/luke-deep-contextualized-entity', 'https://paperswithcode.com/paper/luke-deep-contextualized-entity#code', 'https://paperswithcode.com/paper/deberta-decoding-enhanced-bert-with', 'https://paperswithcode.com/paper/deberta-decoding-enhanced-bert-with#code', 'https://paperswithcode.com/paper/tanda-transfer-and-adapt-pre-trained', 'https://paperswithcode.com/paper/tanda-transfer-and-adapt-pre-trained#code', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining#code', 'https://paperswithcode.com/paper/linguistic-knowledge-as-memory-for-recurrent', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining#code', 'https://paperswithcode.com/paper/self-assttentive-associative-memory', 'https://paperswithcode.com/paper/self-assttentive-associative-memory#code', 'https://paperswithcode.com/paper/memoreader-large-scale-reading-comprehension', 'https://paperswithcode.com/paper/question-directed-graph-attention-network-for', 'https://paperswithcode.com/paper/question-directed-graph-attention-network-for#code', 'https://paperswithcode.com/paper/frustratingly-easy-natural-question-answering', 'https://paperswithcode.com/paper/multi-style-generative-reading-comprehension', 'https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional', 'https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional#code', 'https://paperswithcode.com/paper/language-models-are-unsupervised-multitask', 'https://paperswithcode.com/paper/language-models-are-unsupervised-multitask#code', 'https://paperswithcode.com/paper/learning-dense-representations-of-phrases-at', 'https://paperswithcode.com/paper/learning-dense-representations-of-phrases-at#code', 'https://paperswithcode.com/paper/neural-variational-inference-for-text', 'https://paperswithcode.com/paper/neural-variational-inference-for-text#code', 'https://paperswithcode.com/paper/tanda-transfer-and-adapt-pre-trained', 'https://paperswithcode.com/paper/tanda-transfer-and-adapt-pre-trained#code', 'https://paperswithcode.com/paper/big-bird-transformers-for-longer-sequences', 'https://paperswithcode.com/paper/big-bird-transformers-for-longer-sequences#code', 'https://paperswithcode.com/paper/200302645', 'https://paperswithcode.com/paper/200302645#code', 'https://paperswithcode.com/paper/cluster-former-clustering-based-sparse', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining#code', 'https://paperswithcode.com/paper/improving-machine-reading-comprehension-with', 'https://paperswithcode.com/paper/improving-machine-reading-comprehension-with#code', 'https://paperswithcode.com/paper/fquad-french-question-answering-dataset', 'https://paperswithcode.com/paper/spanbert-improving-pre-training-by', 'https://paperswithcode.com/paper/spanbert-improving-pre-training-by#code', 'https://paperswithcode.com/paper/hyperbolic-representation-learning-for-fast', 'https://paperswithcode.com/paper/hyperbolic-representation-learning-for-fast#code', 'https://paperswithcode.com/paper/spanbert-improving-pre-training-by', 'https://paperswithcode.com/paper/spanbert-improving-pre-training-by#code', 'https://paperswithcode.com/paper/large-scale-simple-question-answering-with', 'https://paperswithcode.com/paper/large-scale-simple-question-answering-with#code', 'https://paperswithcode.com/paper/multi-style-generative-reading-comprehension', 'https://paperswithcode.com/paper/tell-me-why-using-question-answering-as', 'https://paperswithcode.com/paper/deberta-decoding-enhanced-bert-with', 'https://paperswithcode.com/paper/deberta-decoding-enhanced-bert-with#code', 'https://paperswithcode.com/paper/deberta-decoding-enhanced-bert-with', 'https://paperswithcode.com/paper/deberta-decoding-enhanced-bert-with#code', 'https://paperswithcode.com/paper/language-models-are-few-shot-learners', 'https://paperswithcode.com/paper/language-models-are-few-shot-learners#code', 'https://paperswithcode.com/paper/exploring-the-limits-of-transfer-learning', 'https://paperswithcode.com/paper/exploring-the-limits-of-transfer-learning#code', 'https://paperswithcode.com/paper/reclor-a-reading-comprehension-dataset-1', 'https://paperswithcode.com/paper/reclor-a-reading-comprehension-dataset-1#code', 'https://paperswithcode.com/paper/clicr-a-dataset-of-clinical-case-reports-for', 'https://paperswithcode.com/paper/clicr-a-dataset-of-clinical-case-reports-for#code', 'https://paperswithcode.com/paper/flowqa-grasping-flow-in-history-for', 'https://paperswithcode.com/paper/flowqa-grasping-flow-in-history-for#code', 'https://paperswithcode.com/paper/open-question-answering-with-weakly', 'https://paperswithcode.com/paper/a-parallel-hierarchical-model-for-machine', 'https://paperswithcode.com/paper/a-parallel-hierarchical-model-for-machine#code', 'https://paperswithcode.com/paper/exploring-graph-structured-passage', 'https://paperswithcode.com/paper/g-daug-generative-data-augmentation-for', 'https://paperswithcode.com/paper/g-daug-generative-data-augmentation-for#code', 'https://paperswithcode.com/paper/latent-alignment-of-procedural-concepts-in-1', 'https://paperswithcode.com/paper/latent-alignment-of-procedural-concepts-in-1#code', 'https://paperswithcode.com/paper/large-scale-simple-question-answering-with', 'https://paperswithcode.com/paper/large-scale-simple-question-answering-with#code', 'https://paperswithcode.com/paper/a-parallel-hierarchical-model-for-machine', 'https://paperswithcode.com/paper/a-parallel-hierarchical-model-for-machine#code', 'https://paperswithcode.com/paper/product-aware-answer-generation-in-e-commerce', 'https://paperswithcode.com/paper/product-aware-answer-generation-in-e-commerce#code', 'https://paperswithcode.com/paper/spanbert-improving-pre-training-by', 'https://paperswithcode.com/paper/spanbert-improving-pre-training-by#code', 'https://paperswithcode.com/paper/luke-deep-contextualized-entity', 'https://paperswithcode.com/paper/luke-deep-contextualized-entity#code', 'https://paperswithcode.com/paper/unitedqa-a-hybrid-approach-for-open-domain', 'https://paperswithcode.com/paper/unitedqa-a-hybrid-approach-for-open-domain', 'https://paperswithcode.com/paper/unifiedqa-crossing-format-boundaries-with-a', 'https://paperswithcode.com/paper/unifiedqa-crossing-format-boundaries-with-a#code', 'https://paperswithcode.com/paper/domain-specific-language-model-pretraining', 'https://paperswithcode.com/paper/domain-specific-language-model-pretraining#code', 'https://paperswithcode.com/paper/domain-specific-language-model-pretraining', 'https://paperswithcode.com/paper/domain-specific-language-model-pretraining#code', 'https://paperswithcode.com/paper/smart-robust-and-efficient-fine-tuning-for', 'https://paperswithcode.com/paper/smart-robust-and-efficient-fine-tuning-for#code', 'https://paperswithcode.com/paper/sentiment-classification-using-document', 'https://paperswithcode.com/paper/sentiment-classification-using-document#code', 'https://paperswithcode.com/paper/self-explaining-structures-improve-nlp-models', 'https://paperswithcode.com/paper/self-explaining-structures-improve-nlp-models#code', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining#code', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining', 'https://paperswithcode.com/paper/xlnet-generalized-autoregressive-pretraining#code', 'https://paperswithcode.com/paper/a-la-carte-embedding-cheap-but-effective', 'https://paperswithcode.com/paper/a-la-carte-embedding-cheap-but-effective#code', 'https://paperswithcode.com/paper/unsupervised-data-augmentation-1', 'https://paperswithcode.com/paper/unsupervised-data-augmentation-1#code', 'https://paperswithcode.com/paper/unsupervised-data-augmentation-1', 'https://paperswithcode.com/paper/unsupervised-data-augmentation-1#code', 'https://paperswithcode.com/paper/rethinking-attribute-representation-and', 'https://paperswithcode.com/paper/rethinking-attribute-representation-and#code', 'https://paperswithcode.com/paper/grace-gradient-harmonized-and-cascaded', 'https://paperswithcode.com/paper/grace-gradient-harmonized-and-cascaded#code', 'https://paperswithcode.com/paper/gpu-kernels-for-block-sparse-weights', 'https://paperswithcode.com/paper/gpu-kernels-for-block-sparse-weights#code', 'https://paperswithcode.com/paper/revisiting-distributional-correspondence', 'https://paperswithcode.com/paper/revisiting-distributional-correspondence#code', 'https://paperswithcode.com/paper/190600095', 'https://paperswithcode.com/paper/190600095#code', 'https://paperswithcode.com/paper/bb_twtr-at-semeval-2017-task-4-twitter', 'https://paperswithcode.com/paper/bb_twtr-at-semeval-2017-task-4-twitter#code', 'https://paperswithcode.com/paper/robbert-a-dutch-roberta-based-language-model', 'https://paperswithcode.com/paper/robbert-a-dutch-roberta-based-language-model#code', 'https://paperswithcode.com/paper/attentional-encoder-network-for-targeted', 'https://paperswithcode.com/paper/attentional-encoder-network-for-targeted#code', 'https://paperswithcode.com/paper/deep-transfer-learning-baselines-for', 'https://paperswithcode.com/paper/deep-transfer-learning-baselines-for#code', 'https://paperswithcode.com/paper/exploiting-typed-syntactic-dependencies-for', 'https://paperswithcode.com/paper/exploiting-typed-syntactic-dependencies-for#code', 'https://paperswithcode.com/paper/bag-of-tricks-for-efficient-text', 'https://paperswithcode.com/paper/bag-of-tricks-for-efficient-text#code', 'https://paperswithcode.com/paper/mazajak-an-online-arabic-sentiment-analyser', 'https://paperswithcode.com/paper/mazajak-an-online-arabic-sentiment-analyser', 'https://paperswithcode.com/paper/pre-training-with-whole-word-masking-for', 'https://paperswithcode.com/paper/pre-training-with-whole-word-masking-for#code', 'https://paperswithcode.com/paper/pre-training-with-whole-word-masking-for', 'https://paperswithcode.com/paper/pre-training-with-whole-word-masking-for#code', 'https://paperswithcode.com/paper/finbert-financial-sentiment-analysis-with-pre', 'https://paperswithcode.com/paper/finbert-financial-sentiment-analysis-with-pre#code', 'https://paperswithcode.com/paper/finbert-financial-sentiment-analysis-with-pre', 'https://paperswithcode.com/paper/finbert-financial-sentiment-analysis-with-pre#code', 'https://paperswithcode.com/paper/arabert-transformer-based-model-for-arabic', 'https://paperswithcode.com/paper/arabert-transformer-based-model-for-arabic#code', 'https://paperswithcode.com/paper/arabert-transformer-based-model-for-arabic', 'https://paperswithcode.com/paper/arabert-transformer-based-model-for-arabic#code', 'https://paperswithcode.com/paper/arabert-transformer-based-model-for-arabic', 'https://paperswithcode.com/paper/arabert-transformer-based-model-for-arabic#code', 'https://paperswithcode.com/paper/astd-arabic-sentiment-tweets-dataset', 'https://paperswithcode.com/paper/astd-arabic-sentiment-tweets-dataset#code', 'https://paperswithcode.com/paper/what-can-we-learn-from-almost-a-decade-of', 'https://paperswithcode.com/paper/what-can-we-learn-from-almost-a-decade-of#code', 'https://paperswithcode.com/paper/measuring-mathematical-problem-solving-with', 'https://paperswithcode.com/paper/measuring-mathematical-problem-solving-with#code', 'https://paperswithcode.com/paper/long-text-generation-via-adversarial-training', 'https://paperswithcode.com/paper/long-text-generation-via-adversarial-training#code', 'https://paperswithcode.com/paper/long-text-generation-via-adversarial-training', 'https://paperswithcode.com/paper/long-text-generation-via-adversarial-training#code', 'https://paperswithcode.com/paper/sarg-a-novel-semi-autoregressive-generator', 'https://paperswithcode.com/paper/sarg-a-novel-semi-autoregressive-generator#code', 'https://paperswithcode.com/paper/lagging-inference-networks-and-posterior', 'https://paperswithcode.com/paper/lagging-inference-networks-and-posterior#code', 'https://paperswithcode.com/paper/the-gem-benchmark-natural-language-generation', 'https://paperswithcode.com/paper/the-gem-benchmark-natural-language-generation', 'https://paperswithcode.com/paper/the-gem-benchmark-natural-language-generation', 'https://paperswithcode.com/paper/generating-text-through-adversarial-training', 'https://paperswithcode.com/paper/generating-text-through-adversarial-training#code', 'https://paperswithcode.com/paper/sarg-a-novel-semi-autoregressive-generator', 'https://paperswithcode.com/paper/sarg-a-novel-semi-autoregressive-generator#code', 'https://paperswithcode.com/paper/a-graph-to-sequence-model-for-amr-to-text', 'https://paperswithcode.com/paper/a-graph-to-sequence-model-for-amr-to-text#code', 'https://paperswithcode.com/paper/refining-deep-generative-models-via-1', 'https://paperswithcode.com/paper/refining-deep-generative-models-via-1#code', 'https://paperswithcode.com/paper/hardnet-mseg-a-simple-encoder-decoder-polyp', 'https://paperswithcode.com/paper/hardnet-mseg-a-simple-encoder-decoder-polyp#code', 'https://paperswithcode.com/paper/hardnet-mseg-a-simple-encoder-decoder-polyp', 'https://paperswithcode.com/paper/hardnet-mseg-a-simple-encoder-decoder-polyp#code', 'https://paperswithcode.com/paper/transunet-transformers-make-strong-encoders', 'https://paperswithcode.com/paper/transunet-transformers-make-strong-encoders#code', 'https://paperswithcode.com/paper/dc-unet-rethinking-the-u-net-architecture', 'https://paperswithcode.com/paper/dc-unet-rethinking-the-u-net-architecture#code', 'https://paperswithcode.com/paper/kiu-net-overcomplete-convolutional', 'https://paperswithcode.com/paper/kiu-net-overcomplete-convolutional#code', 'https://paperswithcode.com/paper/medical-transformer-gated-axial-attention-for', 'https://paperswithcode.com/paper/medical-transformer-gated-axial-attention-for#code', 'https://paperswithcode.com/paper/medical-transformer-gated-axial-attention-for', 'https://paperswithcode.com/paper/medical-transformer-gated-axial-attention-for#code', 'https://paperswithcode.com/paper/medical-transformer-gated-axial-attention-for', 'https://paperswithcode.com/paper/medical-transformer-gated-axial-attention-for#code', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural#code', 'https://paperswithcode.com/paper/transunet-transformers-make-strong-encoders', 'https://paperswithcode.com/paper/transunet-transformers-make-strong-encoders#code', 'https://paperswithcode.com/paper/pranet-parallel-reverse-attention-network-for', 'https://paperswithcode.com/paper/pranet-parallel-reverse-attention-network-for#code', 'https://paperswithcode.com/paper/hyperdense-net-a-hyper-densely-connected-cnn', 'https://paperswithcode.com/paper/hyperdense-net-a-hyper-densely-connected-cnn#code', 'https://paperswithcode.com/paper/multi-scale-guided-attention-for-medical', 'https://paperswithcode.com/paper/multi-scale-guided-attention-for-medical#code', 'https://paperswithcode.com/paper/multi-scale-guided-attention-for-medical', 'https://paperswithcode.com/paper/multi-scale-guided-attention-for-medical#code', 'https://paperswithcode.com/paper/unet-redesigning-skip-connections-to-exploit', 'https://paperswithcode.com/paper/unet-redesigning-skip-connections-to-exploit#code', 'https://paperswithcode.com/paper/unet-redesigning-skip-connections-to-exploit', 'https://paperswithcode.com/paper/unet-redesigning-skip-connections-to-exploit#code', 'https://paperswithcode.com/paper/bi-directional-convlstm-u-net-with-densley', 'https://paperswithcode.com/paper/bi-directional-convlstm-u-net-with-densley#code', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural#code', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural#code', 'https://paperswithcode.com/paper/resunet-an-advanced-architecture-for-medical', 'https://paperswithcode.com/paper/resunet-an-advanced-architecture-for-medical#code', 'https://paperswithcode.com/paper/resunet-an-advanced-architecture-for-medical', 'https://paperswithcode.com/paper/resunet-an-advanced-architecture-for-medical#code', 'https://paperswithcode.com/paper/ddanet-dual-decoder-attention-network-for', 'https://paperswithcode.com/paper/ddanet-dual-decoder-attention-network-for#code', 'https://paperswithcode.com/paper/automatic-polyp-segmentation-using-u-net', 'https://paperswithcode.com/paper/all-smiles-vae', 'https://paperswithcode.com/paper/molecular-mechanics-driven-graph-neural', 'https://paperswithcode.com/paper/molecular-mechanics-driven-graph-neural#code', 'https://paperswithcode.com/paper/trimnet-learning-molecular-representation', 'https://paperswithcode.com/paper/trimnet-learning-molecular-representation#code', 'https://paperswithcode.com/paper/learning-graph-level-representation-for-drug', 'https://paperswithcode.com/paper/learning-graph-level-representation-for-drug#code', 'https://paperswithcode.com/paper/trimnet-learning-molecular-representation', 'https://paperswithcode.com/paper/trimnet-learning-molecular-representation#code', 'https://paperswithcode.com/paper/trimnet-learning-molecular-representation', 'https://paperswithcode.com/paper/trimnet-learning-molecular-representation#code', 'https://paperswithcode.com/paper/learning-graph-level-representation-for-drug', 'https://paperswithcode.com/paper/learning-graph-level-representation-for-drug#code', 'https://paperswithcode.com/paper/locally-constant-networks', 'https://paperswithcode.com/paper/locally-constant-networks#code', 'https://paperswithcode.com/paper/trimnet-learning-molecular-representation', 'https://paperswithcode.com/paper/trimnet-learning-molecular-representation#code', 'https://paperswithcode.com/paper/optimal-transport-graph-neural-networks', 'https://paperswithcode.com/paper/optimal-transport-graph-neural-networks#code', 'https://paperswithcode.com/paper/attention-based-multi-input-deep-learning', 'https://paperswithcode.com/paper/attention-based-multi-input-deep-learning#code', 'https://paperswithcode.com/paper/multi-resolution-autoregressive-graph-to', 'https://paperswithcode.com/paper/multi-resolution-autoregressive-graph-to#code', 'https://paperswithcode.com/paper/multi-resolution-autoregressive-graph-to', 'https://paperswithcode.com/paper/multi-resolution-autoregressive-graph-to#code', 'https://paperswithcode.com/paper/locally-constant-networks', 'https://paperswithcode.com/paper/locally-constant-networks#code', 'https://paperswithcode.com/paper/d-unet-a-dimension-fusion-u-shape-network-for', 'https://paperswithcode.com/paper/d-unet-a-dimension-fusion-u-shape-network-for#code', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural', 'https://paperswithcode.com/paper/doubleu-net-a-deep-convolutional-neural#code', 'https://paperswithcode.com/paper/a-novel-focal-tversky-loss-function-with', 'https://paperswithcode.com/paper/a-novel-focal-tversky-loss-function-with#code', 'https://paperswithcode.com/paper/automatic-skin-lesion-segmentation-with-fully', 'https://paperswithcode.com/paper/automatic-skin-lesion-segmentation-with-fully#code', 'https://paperswithcode.com/paper/efficient-multi-scale-3d-cnn-with-fully', 'https://paperswithcode.com/paper/efficient-multi-scale-3d-cnn-with-fully#code', 'https://paperswithcode.com/paper/one-pass-multi-task-networks-with-cross-task', 'https://paperswithcode.com/paper/one-pass-multi-task-networks-with-cross-task#code', 'https://paperswithcode.com/paper/learning-semantics-enriched-representation', 'https://paperswithcode.com/paper/learning-semantics-enriched-representation#code', 'https://paperswithcode.com/paper/3d-mri-brain-tumor-segmentation-using', 'https://paperswithcode.com/paper/3d-mri-brain-tumor-segmentation-using#code', 'https://paperswithcode.com/paper/brain-tumor-segmentation-with-deep-neural', 'https://paperswithcode.com/paper/brain-tumor-segmentation-with-deep-neural#code', 'https://paperswithcode.com/paper/one-pass-multi-task-networks-with-cross-task', 'https://paperswithcode.com/paper/one-pass-multi-task-networks-with-cross-task#code', 'https://paperswithcode.com/paper/automatic-brain-tumor-segmentation-using-1', 'https://paperswithcode.com/paper/automatic-brain-tumor-segmentation-using-1#code', 'https://paperswithcode.com/paper/one-pass-multi-task-networks-with-cross-task', 'https://paperswithcode.com/paper/one-pass-multi-task-networks-with-cross-task#code', 'https://paperswithcode.com/paper/covidctnet-an-open-source-deep-learning', 'https://paperswithcode.com/paper/covidctnet-an-open-source-deep-learning#code']\n"
     ]
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "paper=[]\n",
    "#passing specified number of links to fetch project links\n",
    "for x in task_links[0:15]:\n",
    "    req = session.get(x)\n",
    "    bs = BeautifulSoup(req.text, 'html.parser')\n",
    "#Finding table which has all the projects links\n",
    "    table = bs.findAll('table',{\"class\":\"table-striped table-responsive\"})[0]\n",
    "    links=table.findAll('a')\n",
    "#Fetching only relavent links which has project and ignoring others\n",
    "    links1=table.findAll('a', href = re.compile(r'/paper/.*'))\n",
    "#Extracting only links content and appending to list    \n",
    "    for anchor in links1:\n",
    "        href = anchor['href'] \n",
    "        href = 'https://paperswithcode.com' + href\n",
    "        paper.append(href)\n",
    "print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new list\n",
    "final_list=[]\n",
    "title=[]\n",
    "#Fetching metadata information for each link present in list\n",
    "for idp,x in enumerate(paper):\n",
    "    list1=[]    \n",
    "    request = session.get(x)\n",
    "    bs_1 = BeautifulSoup(request.text, 'html.parser')\n",
    "#Extracting title of the project using div class name\n",
    "    title= bs_1.find('div', class_='paper-title').h1\n",
    "    title.append(title.text)\n",
    "#Appending everything to main list\n",
    "    list1.append(title.text)\n",
    "#Extracting domain name of the project using link starting from /task\n",
    "    task = bs_1.findAll('a', href = re.compile(r'/task/*'))\n",
    "    t=[]\n",
    "    for z in task:\n",
    "        t.append(z.text)\n",
    "#Cleaning the data by removing unwanted new line character\n",
    "    t = [x.replace('\\n', '') for x in t]\n",
    "    t = list(set(t))\n",
    "    list1.append(t)\n",
    "#Extracting dataset names used in project using link starting from /dataset\n",
    "    dataset = bs_1.findAll('a', href = re.compile(r'/dataset/*'))\n",
    "    t2=[]\n",
    "    for m in dataset: \n",
    "        t2.append(m.text)\n",
    "#Cleaning the data by removing unwanted new line character and spaces\n",
    "    del t2[0]\n",
    "    t2 = [x.replace('\\n\\n                                      Add a new dataset here\\n                                  ', '') for x in t2]\n",
    "    t2 = [x.replace('\\n', '') for x in t2]\n",
    "    t2 = [x.replace('  ', '') for x in t2]\n",
    "    t2 = list(set(t2))\n",
    "    list1.append(t2)\n",
    "#Extracting github links of the project using link starting from /github.com\n",
    "    git_code = bs_1.findAll('a', href = re.compile(r'https://github.com/.*'))\n",
    "    t3=[]\n",
    "    for y in git_code:\n",
    "        a_href=y['href']\n",
    "        t3.append(a_href)\n",
    "#Cleaning the data by removing unwanted new line character\n",
    "    t3 = [x.replace('\\n', '') for x in t3]\n",
    "    t3 = list(set(t3))\n",
    "    list1.append(t3)\n",
    "    final_list.append(list1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Title  \\\n",
      "0    \\n                  Hierarchical Multi-Scale A...   \n",
      "1    \\n                  Hierarchical Multi-Scale A...   \n",
      "2    \\n                  Rethinking Pre-training an...   \n",
      "3    \\n                  Rethinking Pre-training an...   \n",
      "4    \\n                  ResNeSt: Split-Attention N...   \n",
      "..                                                 ...   \n",
      "679  \\n                  Automatic Brain Tumor Segm...   \n",
      "680  \\n                  One-pass Multi-task Networ...   \n",
      "681  \\n                  One-pass Multi-task Networ...   \n",
      "682  \\n                  CovidCTNet: An Open-Source...   \n",
      "683  \\n                  CovidCTNet: An Open-Source...   \n",
      "\n",
      "                                                Domain  \\\n",
      "0       [SEMANTIC SEGMENTATION, PANOPTIC SEGMENTATION]   \n",
      "1       [SEMANTIC SEGMENTATION, PANOPTIC SEGMENTATION]   \n",
      "2    [DATA AUGMENTATION, SEMANTIC SEGMENTATION, OBJ...   \n",
      "3    [DATA AUGMENTATION, SEMANTIC SEGMENTATION, OBJ...   \n",
      "4    [TRANSFER LEARNING, PANOPTIC SEGMENTATION, OBJ...   \n",
      "..                                                 ...   \n",
      "679  [TUMOR SEGMENTATION, BRAIN TUMOR SEGMENTATION,...   \n",
      "680  [CURRICULUM LEARNING, BRAIN TUMOR SEGMENTATION...   \n",
      "681  [CURRICULUM LEARNING, BRAIN TUMOR SEGMENTATION...   \n",
      "682  [TRANSFER LEARNING, COVID-19 DIAGNOSIS, COVID-...   \n",
      "683  [TRANSFER LEARNING, COVID-19 DIAGNOSIS, COVID-...   \n",
      "\n",
      "                                              Datasets  \\\n",
      "0         [,  Cityscapes ,  Mapillary Vistas Dataset ]   \n",
      "1         [,  Cityscapes ,  Mapillary Vistas Dataset ]   \n",
      "2    [,  ImageNet ,  Objects365 ,  JFT-300M ,  COCO...   \n",
      "3    [,  ImageNet ,  Objects365 ,  JFT-300M ,  COCO...   \n",
      "4    [,  Cityscapes ,  PASCAL Context ,  COCO ,  AD...   \n",
      "..                                                 ...   \n",
      "679                     [,  BraTS 2014 ,  BraTS 2017 ]   \n",
      "680  [,  BraTS 2017 ,  BraTS 2018 ,  BraTS 2013 ,  ...   \n",
      "681  [,  BraTS 2017 ,  BraTS 2018 ,  BraTS 2013 ,  ...   \n",
      "682                                                 []   \n",
      "683                                                 []   \n",
      "\n",
      "                                              GIT link  \n",
      "0    [https://github.com/NVIDIA/semantic-segmentation]  \n",
      "1    [https://github.com/NVIDIA/semantic-segmentation]  \n",
      "2    [https://github.com/tensorflow/tpu/tree/master...  \n",
      "3    [https://github.com/tensorflow/tpu/tree/master...  \n",
      "4    [https://github.com/sailfish009/detectron2-Res...  \n",
      "..                                                 ...  \n",
      "679  [https://github.com/charan223/brain_tumor_topo...  \n",
      "680          [https://github.com/chenhong-zhou/OM-Net]  \n",
      "681          [https://github.com/chenhong-zhou/OM-Net]  \n",
      "682            [https://github.com/mohofar/CovidCtNet]  \n",
      "683            [https://github.com/mohofar/CovidCtNet]  \n",
      "\n",
      "[684 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Converting list to dataframe for further process\n",
    "df = pd.DataFrame(final_list, columns=['Title','Domain','Datasets','GIT link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning dataframe if there are any further unwanted space and \\n in it\n",
    "table = df.replace(r'\\n',  '', regex=True)\n",
    "table = table.replace(r'  ',  '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Title  \\\n",
      "1    Hierarchical Multi-Scale Attention for Semanti...   \n",
      "11   Rethinking Pre-training and Self-training Edit...   \n",
      "13   ResNeSt: Split-Attention Networks Edit social ...   \n",
      "16   Virtual Multi-view Fusion for 3D Semantic Segm...   \n",
      "18   RandLA-Net: Efficient Semantic Segmentation of...   \n",
      "..                                                 ...   \n",
      "673  3D MRI brain tumor segmentation using autoenco...   \n",
      "675  Brain Tumor Segmentation with Deep Neural Netw...   \n",
      "679  Automatic Brain Tumor Segmentation using Casca...   \n",
      "681  One-pass Multi-task Networks with Cross-task G...   \n",
      "683  CovidCTNet: An Open-Source Deep Learning Appro...   \n",
      "\n",
      "                                                Domain  \\\n",
      "1       [SEMANTIC SEGMENTATION, PANOPTIC SEGMENTATION]   \n",
      "11   [DATA AUGMENTATION, SEMANTIC SEGMENTATION, OBJ...   \n",
      "13   [TRANSFER LEARNING, PANOPTIC SEGMENTATION, OBJ...   \n",
      "16   [SCENE UNDERSTANDING, 3D SEMANTIC SEGMENTATION...   \n",
      "18   [3D SEMANTIC SEGMENTATION, SEMANTIC SEGMENTATION]   \n",
      "..                                                 ...   \n",
      "673  [TUMOR SEGMENTATION, BRAIN TUMOR SEGMENTATION,...   \n",
      "675  [TUMOR SEGMENTATION, BRAIN TUMOR SEGMENTATION,...   \n",
      "679  [TUMOR SEGMENTATION, BRAIN TUMOR SEGMENTATION,...   \n",
      "681  [CURRICULUM LEARNING, BRAIN TUMOR SEGMENTATION...   \n",
      "683  [TRANSFER LEARNING, COVID-19 DIAGNOSIS, COVID-...   \n",
      "\n",
      "                                              Datasets  \\\n",
      "1         [,  Cityscapes ,  Mapillary Vistas Dataset ]   \n",
      "11   [,  ImageNet ,  Objects365 ,  JFT-300M ,  COCO...   \n",
      "13   [,  Cityscapes ,  PASCAL Context ,  COCO ,  AD...   \n",
      "16              [,  ADE20K ,  InteriorNet ,  ScanNet ]   \n",
      "18                   [,  Semantic3D ,  SemanticKITTI ]   \n",
      "..                                                 ...   \n",
      "673                     [,  BraTS 2018 ,  BraTS 2017 ]   \n",
      "675       [,  BraTS 2013 ,  BraTS 2015 ,  BraTS 2014 ]   \n",
      "679                     [,  BraTS 2014 ,  BraTS 2017 ]   \n",
      "681  [,  BraTS 2017 ,  BraTS 2018 ,  BraTS 2013 ,  ...   \n",
      "683                                                 []   \n",
      "\n",
      "                                              GIT link  \n",
      "1    [https://github.com/NVIDIA/semantic-segmentation]  \n",
      "11   [https://github.com/tensorflow/tpu/tree/master...  \n",
      "13   [https://github.com/sailfish009/detectron2-Res...  \n",
      "16                                                  []  \n",
      "18   [https://github.com/QingyongHu/RandLA-Net, htt...  \n",
      "..                                                 ...  \n",
      "673  [https://github.com/sinclairjang/3D-MRI-brain-...  \n",
      "675  [https://github.com/peteraugustine/seg3, https...  \n",
      "679  [https://github.com/charan223/brain_tumor_topo...  \n",
      "681          [https://github.com/chenhong-zhou/OM-Net]  \n",
      "683            [https://github.com/mohofar/CovidCtNet]  \n",
      "\n",
      "[236 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Removing duplicates from dataframe by checking title name\n",
    "table=table.drop_duplicates(subset='Title', keep=\"last\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Datasets</th>\n",
       "      <th>GIT link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hierarchical Multi-Scale Attention for Semanti...</td>\n",
       "      <td>[SEMANTIC SEGMENTATION, PANOPTIC SEGMENTATION]</td>\n",
       "      <td>[,  Cityscapes ,  Mapillary Vistas Dataset ]</td>\n",
       "      <td>[https://github.com/NVIDIA/semantic-segmentation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rethinking Pre-training and Self-training Edit...</td>\n",
       "      <td>[DATA AUGMENTATION, SEMANTIC SEGMENTATION, OBJ...</td>\n",
       "      <td>[,  ImageNet ,  Objects365 ,  JFT-300M ,  COCO...</td>\n",
       "      <td>[https://github.com/tensorflow/tpu/tree/master...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ResNeSt: Split-Attention Networks Edit social ...</td>\n",
       "      <td>[TRANSFER LEARNING, PANOPTIC SEGMENTATION, OBJ...</td>\n",
       "      <td>[,  Cityscapes ,  PASCAL Context ,  COCO ,  AD...</td>\n",
       "      <td>[https://github.com/sailfish009/detectron2-Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Virtual Multi-view Fusion for 3D Semantic Segm...</td>\n",
       "      <td>[SCENE UNDERSTANDING, 3D SEMANTIC SEGMENTATION...</td>\n",
       "      <td>[,  ADE20K ,  InteriorNet ,  ScanNet ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandLA-Net: Efficient Semantic Segmentation of...</td>\n",
       "      <td>[3D SEMANTIC SEGMENTATION, SEMANTIC SEGMENTATION]</td>\n",
       "      <td>[,  Semantic3D ,  SemanticKITTI ]</td>\n",
       "      <td>[https://github.com/QingyongHu/RandLA-Net, htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Point Transformer Edit social previewPoint Tra...</td>\n",
       "      <td>[OBJECT CLASSIFICATION, SCENE SEGMENTATION, OB...</td>\n",
       "      <td>[,  ModelNet ,  S3DIS ]</td>\n",
       "      <td>[https://github.com/lucidrains/point-transform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Scene Segmentation with Dual Relation-aware At...</td>\n",
       "      <td>[SEMANTIC SEGMENTATION, SCENE SEGMENTATION]</td>\n",
       "      <td>[,  COCO-Stuff ]</td>\n",
       "      <td>[https://github.com/junfu1115/DRAN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Self-Correction for Human Parsing Edit social ...</td>\n",
       "      <td>[HUMAN PARSING, HUMAN PART SEGMENTATION, SEMAN...</td>\n",
       "      <td>[,  ImageNet ,  LIP ,  PASCAL-Person-Part ,  C...</td>\n",
       "      <td>[https://github.com/PeikeLi/Self-Correction-Hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SGPN: Similarity Group Proposal Network for 3D...</td>\n",
       "      <td>[SCENE SEGMENTATION, 3D INSTANCE SEGMENTATION,...</td>\n",
       "      <td>[,  ShapeNet ,  NYUv2 ,  ScanNet ]</td>\n",
       "      <td>[https://github.com/laughtervv/SGPN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CascadePSP: Toward Class-Agnostic and Very Hig...</td>\n",
       "      <td>[SCENE PARSING, SEMANTIC SEGMENTATION]</td>\n",
       "      <td>[,  ADE20K ,  BIG ,  DUT-OMRON ]</td>\n",
       "      <td>[https://github.com/hkchengrex/CascadePSP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Efficient RGB-D Semantic Segmentation for Indo...</td>\n",
       "      <td>[SEMANTIC SEGMENTATION]</td>\n",
       "      <td>[,  Cityscapes ,  SUN RGB-D ,  NYUv2 ]</td>\n",
       "      <td>[https://github.com/TUI-NICR/ESANet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Prototypical Pseudo Label Denoising and Target...</td>\n",
       "      <td>[UNSUPERVISED DOMAIN ADAPTATION, IMAGE-TO-IMAG...</td>\n",
       "      <td>[,  Cityscapes ,  SYNTHIA ,  GTA5 ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Self-Supervised Model Adaptation for Multimoda...</td>\n",
       "      <td>[SEMANTIC SEGMENTATION, SCENE RECOGNITION]</td>\n",
       "      <td>[,  ImageNet ,  Cityscapes ,  SUN3D ,  SYNTHIA...</td>\n",
       "      <td>[https://github.com/DeepSceneSeg/SSMA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Cloud-Net+: A Cloud Segmentation CNN for Lands...</td>\n",
       "      <td>[CLOUD DETECTION]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://github.com/dveyarangi/cloud-net-plus,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Global Aggregation then Local Distribution in ...</td>\n",
       "      <td>[SCENE UNDERSTANDING, INSTANCE SEGMENTATION, S...</td>\n",
       "      <td>[,  Cityscapes ,  PASCAL VOC 2007 ,  Mapillary...</td>\n",
       "      <td>[https://github.com/lxtGH/GALD-Net, https://gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SkyScapes Fine-Grained Semantic Understanding ...</td>\n",
       "      <td>[EDGE DETECTION, SEMANTIC SEGMENTATION, AUTONO...</td>\n",
       "      <td>[,  ImageNet ,  Cityscapes ,  DOTA ,  COCO ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RELLIS-3D Dataset: Data, Benchmarks and Analys...</td>\n",
       "      <td>[SCENE UNDERSTANDING, 3D SEMANTIC SEGMENTATION...</td>\n",
       "      <td>[,  Cityscapes ,  Mapillary Vistas Dataset ,  ...</td>\n",
       "      <td>[https://github.com/unmannedlab/RELLIS-3D]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Improving Semantic Segmentation via Video Prop...</td>\n",
       "      <td>[VIDEO PREDICTION, SEMANTIC SEGMENTATION]</td>\n",
       "      <td>[,  Cityscapes ,  KITTI ,  SYNTHIA ,  Mapillar...</td>\n",
       "      <td>[https://github.com/NVIDIA/semantic-segmentati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>FasterSeg: Searching for Faster Real-time Sema...</td>\n",
       "      <td>[REAL-TIME SEMANTIC SEGMENTATION, SEMANTIC SEG...</td>\n",
       "      <td>[,  ImageNet ,  Cityscapes ]</td>\n",
       "      <td>[https://github.com/TAMU-VITA/FasterSeg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>A Sim2Real Deep Learning Approach for the Tran...</td>\n",
       "      <td>[CROSS-VIEW IMAGE-TO-IMAGE TRANSLATION, IMAGE ...</td>\n",
       "      <td>[,  Cam2BEV ]</td>\n",
       "      <td>[https://github.com/ika-rwth-aachen/Cam2BEV]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "1   Hierarchical Multi-Scale Attention for Semanti...   \n",
       "11  Rethinking Pre-training and Self-training Edit...   \n",
       "13  ResNeSt: Split-Attention Networks Edit social ...   \n",
       "16  Virtual Multi-view Fusion for 3D Semantic Segm...   \n",
       "18  RandLA-Net: Efficient Semantic Segmentation of...   \n",
       "20  Point Transformer Edit social previewPoint Tra...   \n",
       "24  Scene Segmentation with Dual Relation-aware At...   \n",
       "28  Self-Correction for Human Parsing Edit social ...   \n",
       "31  SGPN: Similarity Group Proposal Network for 3D...   \n",
       "33  CascadePSP: Toward Class-Agnostic and Very Hig...   \n",
       "37  Efficient RGB-D Semantic Segmentation for Indo...   \n",
       "38  Prototypical Pseudo Label Denoising and Target...   \n",
       "42  Self-Supervised Model Adaptation for Multimoda...   \n",
       "44  Cloud-Net+: A Cloud Segmentation CNN for Lands...   \n",
       "46  Global Aggregation then Local Distribution in ...   \n",
       "47  SkyScapes Fine-Grained Semantic Understanding ...   \n",
       "51  RELLIS-3D Dataset: Data, Benchmarks and Analys...   \n",
       "55  Improving Semantic Segmentation via Video Prop...   \n",
       "57  FasterSeg: Searching for Faster Real-time Sema...   \n",
       "59  A Sim2Real Deep Learning Approach for the Tran...   \n",
       "\n",
       "                                               Domain  \\\n",
       "1      [SEMANTIC SEGMENTATION, PANOPTIC SEGMENTATION]   \n",
       "11  [DATA AUGMENTATION, SEMANTIC SEGMENTATION, OBJ...   \n",
       "13  [TRANSFER LEARNING, PANOPTIC SEGMENTATION, OBJ...   \n",
       "16  [SCENE UNDERSTANDING, 3D SEMANTIC SEGMENTATION...   \n",
       "18  [3D SEMANTIC SEGMENTATION, SEMANTIC SEGMENTATION]   \n",
       "20  [OBJECT CLASSIFICATION, SCENE SEGMENTATION, OB...   \n",
       "24        [SEMANTIC SEGMENTATION, SCENE SEGMENTATION]   \n",
       "28  [HUMAN PARSING, HUMAN PART SEGMENTATION, SEMAN...   \n",
       "31  [SCENE SEGMENTATION, 3D INSTANCE SEGMENTATION,...   \n",
       "33             [SCENE PARSING, SEMANTIC SEGMENTATION]   \n",
       "37                            [SEMANTIC SEGMENTATION]   \n",
       "38  [UNSUPERVISED DOMAIN ADAPTATION, IMAGE-TO-IMAG...   \n",
       "42         [SEMANTIC SEGMENTATION, SCENE RECOGNITION]   \n",
       "44                                  [CLOUD DETECTION]   \n",
       "46  [SCENE UNDERSTANDING, INSTANCE SEGMENTATION, S...   \n",
       "47  [EDGE DETECTION, SEMANTIC SEGMENTATION, AUTONO...   \n",
       "51  [SCENE UNDERSTANDING, 3D SEMANTIC SEGMENTATION...   \n",
       "55          [VIDEO PREDICTION, SEMANTIC SEGMENTATION]   \n",
       "57  [REAL-TIME SEMANTIC SEGMENTATION, SEMANTIC SEG...   \n",
       "59  [CROSS-VIEW IMAGE-TO-IMAGE TRANSLATION, IMAGE ...   \n",
       "\n",
       "                                             Datasets  \\\n",
       "1        [,  Cityscapes ,  Mapillary Vistas Dataset ]   \n",
       "11  [,  ImageNet ,  Objects365 ,  JFT-300M ,  COCO...   \n",
       "13  [,  Cityscapes ,  PASCAL Context ,  COCO ,  AD...   \n",
       "16             [,  ADE20K ,  InteriorNet ,  ScanNet ]   \n",
       "18                  [,  Semantic3D ,  SemanticKITTI ]   \n",
       "20                            [,  ModelNet ,  S3DIS ]   \n",
       "24                                   [,  COCO-Stuff ]   \n",
       "28  [,  ImageNet ,  LIP ,  PASCAL-Person-Part ,  C...   \n",
       "31                 [,  ShapeNet ,  NYUv2 ,  ScanNet ]   \n",
       "33                   [,  ADE20K ,  BIG ,  DUT-OMRON ]   \n",
       "37             [,  Cityscapes ,  SUN RGB-D ,  NYUv2 ]   \n",
       "38                [,  Cityscapes ,  SYNTHIA ,  GTA5 ]   \n",
       "42  [,  ImageNet ,  Cityscapes ,  SUN3D ,  SYNTHIA...   \n",
       "44                                                 []   \n",
       "46  [,  Cityscapes ,  PASCAL VOC 2007 ,  Mapillary...   \n",
       "47       [,  ImageNet ,  Cityscapes ,  DOTA ,  COCO ]   \n",
       "51  [,  Cityscapes ,  Mapillary Vistas Dataset ,  ...   \n",
       "55  [,  Cityscapes ,  KITTI ,  SYNTHIA ,  Mapillar...   \n",
       "57                       [,  ImageNet ,  Cityscapes ]   \n",
       "59                                      [,  Cam2BEV ]   \n",
       "\n",
       "                                             GIT link  \n",
       "1   [https://github.com/NVIDIA/semantic-segmentation]  \n",
       "11  [https://github.com/tensorflow/tpu/tree/master...  \n",
       "13  [https://github.com/sailfish009/detectron2-Res...  \n",
       "16                                                 []  \n",
       "18  [https://github.com/QingyongHu/RandLA-Net, htt...  \n",
       "20  [https://github.com/lucidrains/point-transform...  \n",
       "24                [https://github.com/junfu1115/DRAN]  \n",
       "28  [https://github.com/PeikeLi/Self-Correction-Hu...  \n",
       "31               [https://github.com/laughtervv/SGPN]  \n",
       "33         [https://github.com/hkchengrex/CascadePSP]  \n",
       "37               [https://github.com/TUI-NICR/ESANet]  \n",
       "38                                                 []  \n",
       "42             [https://github.com/DeepSceneSeg/SSMA]  \n",
       "44  [https://github.com/dveyarangi/cloud-net-plus,...  \n",
       "46  [https://github.com/lxtGH/GALD-Net, https://gi...  \n",
       "47                                                 []  \n",
       "51         [https://github.com/unmannedlab/RELLIS-3D]  \n",
       "55  [https://github.com/NVIDIA/semantic-segmentati...  \n",
       "57           [https://github.com/TAMU-VITA/FasterSeg]  \n",
       "59       [https://github.com/ika-rwth-aachen/Cam2BEV]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing dataframe as CSV\n",
    "table.to_csv(r'msr_3.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
